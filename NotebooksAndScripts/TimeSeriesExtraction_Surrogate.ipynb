{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d476465-25ed-424d-98be-6159544cbce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utilities as u\n",
    "\n",
    "from keras.models import load_model\n",
    "from pathlib import Path\n",
    "\n",
    "# Ignore Tensorflow Warnings\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '2'\n",
    "\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd4b927-85c9-43db-b5b4-fbaf02076584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model information (used later for image output)\n",
    "model_dir = \"Surrogate\"\n",
    "\n",
    "# Additional run info\n",
    "variables = [\"Hs\", \"Tm02\", \"Dir\"]\n",
    "grid = (160, 160)\n",
    "\n",
    "# Define the point where the time series is extracted (in pixel)\n",
    "xcoord = [69, 86, 69]\n",
    "ycoord = [94, 104, 77] \n",
    "\n",
    "# Test data serials\n",
    "sample_start = 8761\n",
    "sample_end = 17496\n",
    "serial_test = np.arange(sample_start, sample_end+1, 1)\n",
    "\n",
    "# Training data serials\n",
    "sample_ref_start = 24\n",
    "sample_ref_end = 8760\n",
    "serial_ref = np.arange(sample_ref_start, sample_ref_end+1, 1)\n",
    "\n",
    "dim = 1\n",
    "\n",
    "nfreq = 32\n",
    "ntheta = 24\n",
    "\n",
    "# Create output directory if needed\n",
    "path_dir = Path(\"Data/Time_Series\")\n",
    "\n",
    "if not path_dir.exists():\n",
    "    path_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fa0a2b-4ea8-4b2a-9b3f-30c44397bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load normalization constants\n",
    "X_max, X_min = np.load(\"Data/Xmax_Xmin_2018_spectrum.npy\")\n",
    "bat_max, bat_min = np.load(\"Data/bat_max_bat_min_2018_spectrum.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7700183c-fa44-4a86-9554-24221af1fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, var in enumerate(variables): # Load best model of the run\n",
    "\n",
    "    # Prepare file locations for reference and input data\n",
    "    fname_HR = f'Data/HR/{var}/BaskCoast_{var.upper()}_{{}}.npy'\n",
    "    fname_spec = 'Data/Spectrum/BaskCoast_{}.npy'\n",
    "    fname_bat = 'Data/Bathymetry/bat.npy'\n",
    "\n",
    "    fdir = Path(f\"Models/{model_dir}\")\n",
    "    fmodel = fdir / f\"Model_Inp_{var}.hdf5\"\n",
    "    model = load_model(fmodel)\n",
    "    \n",
    "    # Load training data and shift directional data if needed\n",
    "    X, y = u.load_data((fname_HR, fname_spec), serial_test, var, convert=False,\n",
    "                       grid=(nfreq, ntheta))\n",
    "\n",
    "    # Load bathymetry and tile to right length\n",
    "    bat_tot = np.load(fname_bat).reshape((1, *grid, dim))\n",
    "    bat_tot = np.tile(bat_tot, (len(serial_test), 1, 1, 1))\n",
    "    \n",
    "    # Normalize data\n",
    "    X = (X - X_min) / (X_max - X_min)\n",
    "    bat_tot = (bat_tot - bat_min) / (bat_max - bat_min)\n",
    "    \n",
    "    prediction = model.predict([X, bat_tot])\n",
    "    \n",
    "    if var == \"Dir\":     \n",
    "        # Shift directional data back\n",
    "        prediction = (prediction + 255)%360\n",
    "        \n",
    "    for point in zip(xcoord, ycoord):\n",
    "        xi = point[0]\n",
    "        yi = point[1]\n",
    "        \n",
    "        # Load saved array, if calculation was already done before\n",
    "        path_dir = Path(\"Data/Time_Series\")\n",
    "        path_arr = path_dir / f\"Var_{var}_posxy_{xi}_{yi}.npy\"\n",
    "        \n",
    "        # For low-resolution input use array full of nans\n",
    "        lr_input = np.zeros_like(prediction)\n",
    "        lr_input[:] = np.nan\n",
    "\n",
    "        # Save the computed data\n",
    "        if not path_dir.exists():\n",
    "            path_dir.mkdir(parents=True)\n",
    "\n",
    "        np.save(path_arr, np.row_stack(\n",
    "            (prediction[:, xi, yi, 0],\n",
    "             y[:, xi, yi, 0],\n",
    "             lr_input[:, xi, yi, 0])))\n",
    "\n",
    "    del X, y, bat_tot, prediction\n",
    "    \n",
    "    # Extract time series for HR training data in similar fashion\n",
    "    # Prepare file locations for reference\n",
    "    fname_HR = f'Data/HR/{var}/BaskCoast_{var.upper()}_{{}}.npy'\n",
    "\n",
    "    # Define output directory\n",
    "    path_dir = Path(\"Data/Time_Series\")\n",
    "    path_arr = path_dir / f\"Ref_Var_{var}_posxy_{xi}_{yi}.npy\"\n",
    "\n",
    "    y = np.zeros((len(serial_ref), grid[0], grid[1], dim))\n",
    "\n",
    "    # Load reference training data\n",
    "    for i, s in enumerate(serial_ref):\n",
    "        y[i, :, :, 0] = np.load(fname_HR.format(s))\n",
    "\n",
    "    # Extract time series at given location\n",
    "    ref = y[:, xi, yi, 0]\n",
    "\n",
    "    np.save(path_arr, ref)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
