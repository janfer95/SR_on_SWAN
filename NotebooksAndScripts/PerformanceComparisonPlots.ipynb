{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3633ea39-11bc-4ced-9025-dbcd36fa0730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utilities as u\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-deep')\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238cf5a9-252a-4b22-a157-21b3de5e1189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder names and how model names should appear\n",
    "dirs = [\"Subpixel\", \"SubpixelDilated\", \"OriginalFukami\", \"DataAugmented\"]\n",
    "legends = [\"Subpixel\", \"Subpixel Dilated\", \"Original Fukami\", \"Data Augmented\"]\n",
    "legends_abbr = [\"S\", \"SD\", \"OF\", \"DA\"]\n",
    "variables = [\"Hs\", \"Tm02\", \"Dir\"]\n",
    "markers = [\"o\", \"s\", \"^\", \"D\"]\n",
    "units = {0: \"[m]\", 1: \"[s]\", 2: \"[Â°]\"}\n",
    "\n",
    "# Used to plot the mean in the same color\n",
    "colors = sns.color_palette()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e05ab8-81ba-4bc0-bf16-0f93d520aca3",
   "metadata": {},
   "source": [
    "# Plot performances with their means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f76d3f8-fc07-44ea-99f6-83024cac21b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELSIZE = 15\n",
    "TITLESIZE = 16\n",
    "TICKLABELSIZE = 13\n",
    "LEGENDFONTSIZE = 12\n",
    "\n",
    "fig, axs = plt.subplots(1, len(variables), figsize=(15,6))\n",
    "for i, var in enumerate(variables):\n",
    "    for j, dr in enumerate(dirs):\n",
    "        # Get the performance on test data from summary files \n",
    "        evals, _ = u.extract_time_and_eval(dr, var)\n",
    "        # Compute the corresponding means and plot them\n",
    "        axs[i].scatter(len(evals)*[j], evals, color=colors[j], label=legends[j],\n",
    "                       marker=markers[j], s=100, alpha=0.8)\n",
    "        mean_evals = sum(evals)/len(evals)\n",
    "        axs[i].scatter([j], mean_evals, color=colors[j], marker=markers[j],\n",
    "                       edgecolor=\"k\", linewidth=1.5, s=150)\n",
    "        \n",
    "        \n",
    "    axs[i].tick_params(axis=\"both\", labelsize=TICKLABELSIZE)\n",
    "    axs[i].grid(True, axis=\"both\", ls=\"--\")\n",
    "    axs[i].set_axisbelow(True)\n",
    "    axs[i].xaxis.set_ticks([0,1,2,3], legends_abbr)\n",
    "    axs[i].set_title(\"{} {}\".format(var, units[i]), size=TITLESIZE)\n",
    "    \n",
    "    \n",
    "axs[0].set_ylabel(\"MAE over Test Set\", size=LABELSIZE)\n",
    "axs[1].legend(loc='upper center', bbox_to_anchor=(0.5, 1.2),\n",
    "          fancybox=True, shadow=True, ncol=2, fontsize=LEGENDFONTSIZE)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0421402e-3b60-4d50-9e6d-cd3b64ff36ec",
   "metadata": {},
   "source": [
    "# Alternative Plot with training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef72355-32c9-4aff-8a62-5fd955013d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELSIZE = 15\n",
    "TITLESIZE = 16\n",
    "TICKLABELSIZE = 13\n",
    "LEGENDFONTSIZE = 12\n",
    "TIME_RANGE_LOWER = 1.2\n",
    "TIME_RANGE_UPPER = 4.7\n",
    "\n",
    "fig, axs = plt.subplots(1, len(variables), figsize=(15,6))\n",
    "for i, var in enumerate(variables):\n",
    "    for j, dr in enumerate(dirs):\n",
    "        # Get the performance on test data from summary files \n",
    "        evals, times = u.extract_time_and_eval(dr, var)\n",
    "        # Pick out the two points that are compared\n",
    "        if (j == 0 and i == 0):\n",
    "            axs[i].scatter(times, evals, color=colors[j], label=legends[j],\n",
    "                           marker=markers[j], s=100, alpha=0.8)\n",
    "            axs[i].scatter(times[3], evals[3], color=colors[j], marker=markers[j],\n",
    "                           edgecolor=\"k\", linewidth=3, s=200)\n",
    "            \n",
    "        elif (j == 2 and i == 0):\n",
    "            axs[i].scatter(times, evals, color=colors[j], label=legends[j],\n",
    "                           marker=markers[j], s=100, alpha=0.8)\n",
    "            axs[i].scatter(times[5], evals[5], color=colors[j], marker=markers[j],\n",
    "                           edgecolor=\"k\", linewidth=3, s=200)\n",
    "            \n",
    "        else:\n",
    "            axs[i].scatter(times, evals, color=colors[j], label=legends[j],\n",
    "                           marker=markers[j], s=100, alpha=0.8)\n",
    "        \n",
    "        \n",
    "    axs[i].set_xlabel(\"Training Time [h]\", size=LABELSIZE)\n",
    "    axs[i].set_xlim(TIME_RANGE_LOWER, TIME_RANGE_UPPER)\n",
    "    axs[i].tick_params(axis=\"both\", labelsize=TICKLABELSIZE)\n",
    "    axs[i].grid(True, axis=\"both\", ls=\"--\")\n",
    "    axs[i].set_axisbelow(True)\n",
    "    axs[i].set_title(\"{} {}\".format(var, units[i]), size=TITLESIZE)\n",
    "    \n",
    "    \n",
    "axs[0].set_ylabel(\"MAE over Test Set\", size=LABELSIZE)\n",
    "axs[1].legend(loc='upper center', bbox_to_anchor=(0.5, 1.2),\n",
    "          fancybox=True, shadow=True, ncol=2, fontsize=LEGENDFONTSIZE)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73686e0-136d-4ea0-b435-fef0f287047d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
