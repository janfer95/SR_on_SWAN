{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad1606-ec8a-4b09-9900-220a61c2524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utilities as u\n",
    "import subpixellayer as sl # Is important for the subpixel layer\n",
    "\n",
    "from keras.models import load_model\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Ignore Tensorflow Warnings and other Tensorflow options\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '2'\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891b9f4f-2713-4801-84d5-bdc0fde28612",
   "metadata": {},
   "source": [
    "# Extract time series at given locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6ab21a-bf00-4845-9b61-2ac68d26be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model directory / Network architecture (e.g. DataAugmented, OriginalFukami,...)\n",
    "model_dir = \"Subpixel\"\n",
    "\n",
    "# Additional run info\n",
    "variables = [\"Hs\", \"Tm02\", \"Dir\"]\n",
    "\n",
    "grid = (10, 10)\n",
    "upfactor = 16\n",
    "\n",
    "# Define the points where the time series are extracted (in pixel)\n",
    "xcoords = [69, 86, 69]\n",
    "ycoords = [94, 104, 77] \n",
    "\n",
    "# Test data serials\n",
    "sample_start = 8761\n",
    "sample_end = 17496\n",
    "serial = np.arange(sample_start, sample_end+1, 1)\n",
    "\n",
    "# Training data serials\n",
    "sample_ref_start = 24\n",
    "sample_ref_end = 8760\n",
    "serial_ref = np.arange(sample_ref_start, sample_ref_end+1, 1)\n",
    "\n",
    "dim = 1\n",
    "\n",
    "# Save the figure?\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e29d3-fe2c-432d-8a8a-ab0ef3ae9f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for point in zip(xcoords, ycoords):\n",
    "    xi = point[0]\n",
    "    yi = point[1]\n",
    "    \n",
    "    for k, var in enumerate(variables):# Load best model of the run\n",
    "        fdir = \"Models/{}\".format(model_dir)\n",
    "        fmodel = \"Model_Inp_{}.hdf5\".format(var)\n",
    "        fmodel = os.path.join(fdir, fmodel)\n",
    "        model = load_model(fmodel)\n",
    "\n",
    "        # Prepare file locations for reference and input data\n",
    "        fname_HR = './Data/HR/{}/BaskCoast_{}_{{}}.npy'\n",
    "        fname_HR = fname_HR.format(var, var.upper())\n",
    "        fname_LR = './Data/LR/{}/BaskCoast_{}_{{}}.npy'\n",
    "        fname_LR = fname_LR.format(var, var.upper())\n",
    "\n",
    "        # Define output directory\n",
    "        path_dir = \"./Data/Time_Series\"\n",
    "        path_arr = path_dir + \"/Var_{}_posxy_{}_{}.npy\"\n",
    "        path_arr = path_arr.format(var, xi, yi)\n",
    "\n",
    "        # Load the test data set\n",
    "        X, y = u.load_data((fname_HR, fname_LR), serial, var)\n",
    "        \n",
    "        # Convert NaN to zero\n",
    "        X = np.nan_to_num(X)\n",
    "        y = np.nan_to_num(y)\n",
    "\n",
    "        # Evaluate model on whole data set\n",
    "        prediction = model.predict(X)\n",
    "        \n",
    "        # Extract time series at location (adjust position for LR input)\n",
    "        X = X[:, int(xi/upfactor), int(yi/upfactor), 0]\n",
    "        y = y[:, xi, yi, 0]\n",
    "        prediction = prediction[:, xi, yi, 0]\n",
    "        \n",
    "        # Shift directional values back if necessary\n",
    "        X = (X + 255)%360\n",
    "        y = (y + 255)%360\n",
    "        prediction = (prediction + 255)%360\n",
    "        \n",
    "        # Save the computed data\n",
    "        if not os.path.isdir(path_dir):\n",
    "            os.makedirs(path_dir)\n",
    "\n",
    "        np.save(path_arr, np.r_[prediction, y, X])\n",
    "        \n",
    "\n",
    "        # Extract time series for HR training data in similar fashion\n",
    "        # Prepare file locations for reference and input data\n",
    "        fname_HR = './Data/HR/{}/BaskCoast_{}_{{}}.npy'\n",
    "        fname_HR = fname_HR.format(var, var.upper())\n",
    "\n",
    "        # Define output directory\n",
    "        path_dir = \"./Data/Time_Series\"\n",
    "        path_arr = path_dir + \"/Ref_Var_{}_posxy_{}_{}.npy\"\n",
    "        path_arr = path_arr.format(var, xi, yi)\n",
    "\n",
    "        y = np.zeros((len(serial_ref), grid[0]*upfactor, grid[1]*upfactor, dim))\n",
    "\n",
    "        # Load reference training data\n",
    "        for i, s in enumerate(serial_ref):\n",
    "            y[i,:,:,0] = np.load(fname_HR.format(s))\n",
    "\n",
    "        # Extract time series at given location\n",
    "        ref = y[:,xi,yi,0]\n",
    "\n",
    "        # Save the loaded data\n",
    "        if not os.path.isdir(path_dir):\n",
    "            os.makedirs(path_dir)\n",
    "\n",
    "        np.save(path_arr, ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42c0f55-19c0-4b62-af01-42921c3d54bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
